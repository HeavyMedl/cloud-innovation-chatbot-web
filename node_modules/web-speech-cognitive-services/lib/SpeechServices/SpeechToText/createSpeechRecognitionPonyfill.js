"use strict";

var _interopRequireDefault = require("@babel/runtime/helpers/interopRequireDefault");

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = void 0;

var _objectSpread2 = _interopRequireDefault(require("@babel/runtime/helpers/objectSpread"));

var _regenerator = _interopRequireDefault(require("@babel/runtime/regenerator"));

var _classCallCheck2 = _interopRequireDefault(require("@babel/runtime/helpers/classCallCheck"));

var _createClass2 = _interopRequireDefault(require("@babel/runtime/helpers/createClass"));

var _possibleConstructorReturn2 = _interopRequireDefault(require("@babel/runtime/helpers/possibleConstructorReturn"));

var _getPrototypeOf2 = _interopRequireDefault(require("@babel/runtime/helpers/getPrototypeOf"));

var _inherits2 = _interopRequireDefault(require("@babel/runtime/helpers/inherits"));

var _asyncToGenerator2 = _interopRequireDefault(require("@babel/runtime/helpers/asyncToGenerator"));

var _memoizeOne = _interopRequireDefault(require("memoize-one"));

var _cognitiveServiceEventResultToWebSpeechRecognitionResultList = _interopRequireDefault(require("./cognitiveServiceEventResultToWebSpeechRecognitionResultList"));

var _createPromiseQueue = _interopRequireDefault(require("../../Util/createPromiseQueue"));

var _DOMEventEmitter2 = _interopRequireDefault(require("../../Util/DOMEventEmitter"));

var _SpeechGrammarList = _interopRequireDefault(require("./SpeechGrammarList"));

var _SpeechSDK = _interopRequireDefault(require("../SpeechSDK"));

// https://docs.microsoft.com/en-us/javascript/api/microsoft-cognitiveservices-speech-sdk/speechconfig?view=azure-node-latest#outputformat
// {
//   "RecognitionStatus": "Success",
//   "Offset": 900000,
//   "Duration": 49000000,
//   "NBest": [
//     {
//       "Confidence": 0.738919,
//       "Lexical": "second",
//       "ITN": "second",
//       "MaskedITN": "second",
//       "Display": "Second."
//     }
//   ]
// }
// {
//   "RecognitionStatus": "InitialSilenceTimeout",
//   "Offset": 50000000,
//   "Duration": 0
// }
var AudioConfig = _SpeechSDK.default.AudioConfig,
    OutputFormat = _SpeechSDK.default.OutputFormat,
    ResultReason = _SpeechSDK.default.ResultReason,
    SpeechConfig = _SpeechSDK.default.SpeechConfig,
    SpeechRecognizer = _SpeechSDK.default.SpeechRecognizer;

function serializeRecognitionResult(_ref) {
  var duration = _ref.duration,
      errorDetails = _ref.errorDetails,
      json = _ref.json,
      offset = _ref.offset,
      properties = _ref.properties,
      reason = _ref.reason,
      resultId = _ref.resultId,
      text = _ref.text;
  return {
    duration: duration,
    errorDetails: errorDetails,
    json: JSON.parse(json),
    offset: offset,
    properties: properties,
    reason: reason,
    resultId: resultId,
    text: text
  };
}

var _default =
/*#__PURE__*/
(0, _asyncToGenerator2.default)(
/*#__PURE__*/
_regenerator.default.mark(function _callee3() {
  var _ref3,
      authorizationToken,
      _ref3$region,
      region,
      subscriptionKey,
      _ref3$textNormalizati,
      textNormalization,
      audioConfig,
      SpeechRecognition,
      _args4 = arguments;

  return _regenerator.default.wrap(function _callee3$(_context4) {
    while (1) {
      switch (_context4.prev = _context4.next) {
        case 0:
          _ref3 = _args4.length > 0 && _args4[0] !== undefined ? _args4[0] : {}, authorizationToken = _ref3.authorizationToken, _ref3$region = _ref3.region, region = _ref3$region === void 0 ? 'westus' : _ref3$region, subscriptionKey = _ref3.subscriptionKey, _ref3$textNormalizati = _ref3.textNormalization, textNormalization = _ref3$textNormalizati === void 0 ? 'display' : _ref3$textNormalizati;

          if (!(!authorizationToken && !subscriptionKey)) {
            _context4.next = 6;
            break;
          }

          console.warn('Either authorizationToken or subscriptionKey must be specified');
          return _context4.abrupt("return", {});

        case 6:
          if (!(!window.navigator.mediaDevices || !window.navigator.mediaDevices.getUserMedia)) {
            _context4.next = 9;
            break;
          }

          console.warn('This browser does not support WebRTC and it will not work with Cognitive Services Speech Services.');
          return _context4.abrupt("return", {});

        case 9:
          audioConfig = AudioConfig.fromDefaultMicrophoneInput();

          SpeechRecognition =
          /*#__PURE__*/
          function (_DOMEventEmitter) {
            (0, _inherits2.default)(SpeechRecognition, _DOMEventEmitter);

            function SpeechRecognition() {
              var _this;

              (0, _classCallCheck2.default)(this, SpeechRecognition);
              _this = (0, _possibleConstructorReturn2.default)(this, (0, _getPrototypeOf2.default)(SpeechRecognition).call(this, ['audiostart', 'soundstart', 'speechstart', 'speechend', 'soundend', 'audioend', 'result', 'nomatch', 'error', 'start', 'end', 'cognitiveservices']));
              _this._continuous = false;
              _this._interimResults = false;
              _this._lang = typeof window !== 'undefined' ? window.document.documentElement.getAttribute('lang') || window.navigator.language : 'en-US';
              _this._maxAlternatives = 1;
              return _this;
            }

            (0, _createClass2.default)(SpeechRecognition, [{
              key: "createRecognizer",
              value: function () {
                var _createRecognizer = (0, _asyncToGenerator2.default)(
                /*#__PURE__*/
                _regenerator.default.mark(function _callee() {
                  var speechConfig;
                  return _regenerator.default.wrap(function _callee$(_context) {
                    while (1) {
                      switch (_context.prev = _context.next) {
                        case 0:
                          if (!authorizationToken) {
                            _context.next = 16;
                            break;
                          }

                          _context.t1 = SpeechConfig;

                          if (!(typeof authorizationToken === 'function')) {
                            _context.next = 8;
                            break;
                          }

                          _context.next = 5;
                          return authorizationToken();

                        case 5:
                          _context.t2 = _context.sent;
                          _context.next = 11;
                          break;

                        case 8:
                          _context.next = 10;
                          return authorizationToken;

                        case 10:
                          _context.t2 = _context.sent;

                        case 11:
                          _context.t3 = _context.t2;
                          _context.t4 = region;
                          _context.t0 = _context.t1.fromAuthorizationToken.call(_context.t1, _context.t3, _context.t4);
                          _context.next = 17;
                          break;

                        case 16:
                          _context.t0 = SpeechConfig.fromSubscription(subscriptionKey, region);

                        case 17:
                          speechConfig = _context.t0;
                          speechConfig.outputFormat = OutputFormat.Detailed;
                          speechConfig.speechRecognitionLanguage = this.lang || 'en-US';
                          return _context.abrupt("return", new SpeechRecognizer(speechConfig, audioConfig));

                        case 21:
                        case "end":
                          return _context.stop();
                      }
                    }
                  }, _callee, this);
                }));

                return function createRecognizer() {
                  return _createRecognizer.apply(this, arguments);
                };
              }()
            }, {
              key: "emitCognitiveServices",
              value: function emitCognitiveServices(type, event) {
                this.emit('cognitiveservices', (0, _objectSpread2.default)({}, event, {
                  subType: type
                }));
              }
            }, {
              key: "abort",
              value: function abort() {}
            }, {
              key: "start",
              value: function start() {
                var _this2 = this;

                if (this.continuous) {
                  throw new Error('Continuous mode is not supported.');
                } else {
                  this._startOnce().catch(function (err) {
                    console.error(err);

                    _this2.emit('error', {
                      error: err,
                      message: err && err.message
                    });
                  });
                }
              }
            }, {
              key: "_startOnce",
              value: function () {
                var _startOnce2 = (0, _asyncToGenerator2.default)(
                /*#__PURE__*/
                _regenerator.default.mark(function _callee2() {
                  var _this3 = this;

                  var recognizer, queue, lastRecognizingResults, speechStarted, stopping, audioStarted, finalEvent, _loop, loop, _ret;

                  return _regenerator.default.wrap(function _callee2$(_context3) {
                    while (1) {
                      switch (_context3.prev = _context3.next) {
                        case 0:
                          _context3.next = 2;
                          return this.createRecognizer();

                        case 2:
                          recognizer = _context3.sent;
                          queue = (0, _createPromiseQueue.default)();

                          recognizer.canceled = function (_, _ref4) {
                            var errorDetails = _ref4.errorDetails,
                                offset = _ref4.offset,
                                reason = _ref4.reason,
                                sessionId = _ref4.sessionId;
                            queue.push({
                              canceled: {
                                errorDetails: errorDetails,
                                offset: offset,
                                reason: reason,
                                sessionId: sessionId
                              }
                            });
                          };

                          recognizer.recognized = function (_, _ref5) {
                            var offset = _ref5.offset,
                                result = _ref5.result,
                                sessionId = _ref5.sessionId;
                            queue.push({
                              recognized: {
                                offset: offset,
                                result: serializeRecognitionResult(result),
                                sessionId: sessionId
                              }
                            });
                          };

                          recognizer.recognizing = function (_, _ref6) {
                            var offset = _ref6.offset,
                                result = _ref6.result,
                                sessionId = _ref6.sessionId;
                            queue.push({
                              recognizing: {
                                offset: offset,
                                result: serializeRecognitionResult(result),
                                sessionId: sessionId
                              }
                            });
                          };

                          recognizer.recognizeOnceAsync(function (result) {
                            return queue.push({
                              success: serializeRecognitionResult(result)
                            });
                          }, function (err) {
                            return queue.push({
                              error: err
                            });
                          });

                          this.abort = function () {
                            return queue.push({
                              abort: {}
                            });
                          };

                          this.stop = function () {
                            return queue.push({
                              stop: {}
                            });
                          };

                          _loop =
                          /*#__PURE__*/
                          _regenerator.default.mark(function _loop(loop) {
                            var event, abort, canceled, error, recognized, recognizing, stop, success, errorMessage;
                            return _regenerator.default.wrap(function _loop$(_context2) {
                              while (1) {
                                switch (_context2.prev = _context2.next) {
                                  case 0:
                                    _context2.next = 2;
                                    return queue.shift();

                                  case 2:
                                    event = _context2.sent;
                                    abort = event.abort, canceled = event.canceled, error = event.error, recognized = event.recognized, recognizing = event.recognizing, stop = event.stop, success = event.success; // We are emitting event "cognitiveservices" for debugging purpose

                                    Object.keys(event).forEach(function (name) {
                                      return _this3.emitCognitiveServices(name, event[name]);
                                    });
                                    errorMessage = error ? error : canceled && canceled.errorDetails;

                                    if (!(errorMessage && /Permission\sdenied/.test(errorMessage))) {
                                      _context2.next = 9;
                                      break;
                                    }

                                    finalEvent = {
                                      error: 'not-allowed',
                                      type: 'error'
                                    };
                                    return _context2.abrupt("return", "break");

                                  case 9:
                                    if (!loop) {
                                      _this3.emit('start');

                                      _this3.emit('audiostart');

                                      audioStarted = true;
                                    }

                                    if (!errorMessage) {
                                      _context2.next = 15;
                                      break;
                                    }

                                    if (/1006/.test(errorMessage)) {
                                      finalEvent = {
                                        error: 'network',
                                        type: 'error'
                                      };
                                    } else {
                                      finalEvent = {
                                        error: 'unknown',
                                        type: 'error'
                                      };
                                    }

                                    return _context2.abrupt("return", "break");

                                  case 15:
                                    if (!(abort || stop)) {
                                      _context2.next = 21;
                                      break;
                                    }

                                    stopping = true;

                                    if (abort) {
                                      finalEvent = {
                                        error: 'aborted',
                                        type: 'error'
                                      };
                                    } else if (lastRecognizingResults) {
                                      lastRecognizingResults.isFinal = true;
                                      finalEvent = {
                                        results: lastRecognizingResults,
                                        type: 'result'
                                      };
                                    }

                                    if (speechStarted) {
                                      _this3.emit('speechend');

                                      _this3.emit('soundend');

                                      speechStarted = false;
                                    }

                                    _context2.next = 33;
                                    break;

                                  case 21:
                                    if (stopping) {
                                      _context2.next = 33;
                                      break;
                                    }

                                    if (!(recognized && recognized.result && recognized.result.reason === ResultReason.NoMatch)) {
                                      _context2.next = 26;
                                      break;
                                    }

                                    finalEvent = {
                                      error: 'no-speech',
                                      type: 'error'
                                    };
                                    _context2.next = 33;
                                    break;

                                  case 26:
                                    if (!loop) {
                                      _this3.emit('soundstart');

                                      _this3.emit('speechstart');

                                      speechStarted = true;
                                    }

                                    if (!recognized) {
                                      _context2.next = 32;
                                      break;
                                    }

                                    finalEvent = {
                                      results: (0, _cognitiveServiceEventResultToWebSpeechRecognitionResultList.default)(recognized.result, {
                                        maxAlternatives: _this3.maxAlternatives,
                                        textNormalization: textNormalization
                                      }),
                                      type: 'result'
                                    };
                                    return _context2.abrupt("return", "break");

                                  case 32:
                                    if (recognizing) {
                                      lastRecognizingResults = (0, _cognitiveServiceEventResultToWebSpeechRecognitionResultList.default)(recognizing.result, {
                                        maxAlternatives: _this3.maxAlternatives,
                                        textNormalization: textNormalization
                                      });
                                      _this3.interimResults && _this3.emit('result', {
                                        results: lastRecognizingResults
                                      });
                                    }

                                  case 33:
                                    if (!(error || success)) {
                                      _context2.next = 35;
                                      break;
                                    }

                                    return _context2.abrupt("return", "break");

                                  case 35:
                                  case "end":
                                    return _context2.stop();
                                }
                              }
                            }, _loop, this);
                          });
                          loop = 0;

                        case 12:
                          return _context3.delegateYield(_loop(loop), "t0", 13);

                        case 13:
                          _ret = _context3.t0;

                          if (!(_ret === "break")) {
                            _context3.next = 16;
                            break;
                          }

                          return _context3.abrupt("break", 19);

                        case 16:
                          loop++;
                          _context3.next = 12;
                          break;

                        case 19:
                          // TODO: We should emit "audioend", "result", or "error" here
                          //       This is for mimicking stop() behavior, "audioend" should not fire too early until we received the last "recognized" event
                          if (speechStarted) {
                            this.emit('speechend');
                            this.emit('soundend');
                          }

                          if (audioStarted) {
                            this.emit('audioend');
                          }

                          if (finalEvent) {
                            this.emit(finalEvent.type, finalEvent);
                          } // Even though there is no "start" event emitted, we will still emit "end" event
                          // This is mainly for "microphone blocked" story.


                          this.emit('end');
                          recognizer.dispose();

                        case 24:
                        case "end":
                          return _context3.stop();
                      }
                    }
                  }, _callee2, this);
                }));

                return function _startOnce() {
                  return _startOnce2.apply(this, arguments);
                };
              }()
            }, {
              key: "stop",
              value: function stop() {}
            }, {
              key: "continuous",
              get: function get() {
                return this._continuous;
              },
              set: function set(value) {
                value && console.warn("Speech Services: Cannot set continuous to ".concat(value, ", this feature is not supported."));
              }
            }, {
              key: "interimResults",
              get: function get() {
                return this._interimResults;
              },
              set: function set(value) {
                this._interimResults = value;
              }
            }, {
              key: "maxAlternatives",
              get: function get() {
                return this._maxAlternatives;
              },
              set: function set(value) {
                this._maxAlternatives = value;
              }
            }, {
              key: "lang",
              get: function get() {
                return this._lang;
              },
              set: function set(value) {
                this._lang = value;
              }
            }]);
            return SpeechRecognition;
          }(_DOMEventEmitter2.default);

          return _context4.abrupt("return", {
            SpeechGrammarList: _SpeechGrammarList.default,
            SpeechRecognition: SpeechRecognition
          });

        case 12:
        case "end":
          return _context4.stop();
      }
    }
  }, _callee3, this);
}));

exports.default = _default;
//# sourceMappingURL=createSpeechRecognitionPonyfill.js.map
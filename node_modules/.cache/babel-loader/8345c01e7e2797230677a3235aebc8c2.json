{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireWildcard = require(\"@babel/runtime/helpers/interopRequireWildcard\");\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _objectWithoutProperties2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectWithoutProperties\"));\n\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread\"));\n\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\n\nvar _asyncToGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncToGenerator\"));\n\nvar _classCallCheck2 = _interopRequireDefault(require(\"@babel/runtime/helpers/classCallCheck\"));\n\nvar _createClass2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createClass\"));\n\nvar _possibleConstructorReturn2 = _interopRequireDefault(require(\"@babel/runtime/helpers/possibleConstructorReturn\"));\n\nvar _getPrototypeOf2 = _interopRequireDefault(require(\"@babel/runtime/helpers/getPrototypeOf\"));\n\nvar _inherits2 = _interopRequireDefault(require(\"@babel/runtime/helpers/inherits\"));\n\nvar CognitiveSpeech = _interopRequireWildcard(require(\"microsoft-speech-browser-sdk\"));\n\nvar _eventAsPromise = _interopRequireDefault(require(\"event-as-promise\"));\n\nvar _memoizeOne = _interopRequireDefault(require(\"memoize-one\"));\n\nvar _DOMEventEmitter2 = _interopRequireDefault(require(\"../Util/DOMEventEmitter\"));\n\nvar _fetchAuthorizationToken = _interopRequireDefault(require(\"../fetchAuthorizationToken\"));\n\nvar _SpeechGrammarList = _interopRequireDefault(require(\"./SpeechGrammarList\"));\n\nfunction buildSpeechResult(transcript, confidence, isFinal) {\n  var result = [{\n    confidence: confidence,\n    transcript: transcript\n  }];\n  result.isFinal = isFinal;\n  return {\n    results: [result],\n    type: 'result'\n  };\n}\n\nfunction bingSpeechPromisify(fn) {\n  return function () {\n    try {\n      var _sink = new CognitiveSpeech.Sink();\n\n      fn().then(_sink.Resolve, _sink.Reject);\n      return new CognitiveSpeech.Promise(_sink);\n    } catch (err) {\n      sink.Reject(err.message);\n    }\n  };\n}\n\nvar _default = function _default(_ref) {\n  var authorizationToken = _ref.authorizationToken,\n      subscriptionKey = _ref.subscriptionKey,\n      textNormalization = _ref.textNormalization;\n\n  if (!authorizationToken && !subscriptionKey) {\n    console.warn('Either authorization token or subscription key must be specified');\n    return {};\n  } else if (!window.navigator.mediaDevices || !window.navigator.mediaDevices.getUserMedia) {\n    console.warn('This browser does not support WebRTC and it will not work with Cognitive Services Speech Services.');\n    return {};\n  }\n\n  var SpeechRecognition =\n  /*#__PURE__*/\n  function (_DOMEventEmitter) {\n    (0, _inherits2.default)(SpeechRecognition, _DOMEventEmitter);\n\n    function SpeechRecognition() {\n      var _this;\n\n      (0, _classCallCheck2.default)(this, SpeechRecognition);\n      _this = (0, _possibleConstructorReturn2.default)(this, (0, _getPrototypeOf2.default)(SpeechRecognition).call(this, ['audiostart', 'soundstart', 'speechstart', 'speechend', 'soundend', 'audioend', 'result', 'nomatch', 'error', 'start', 'end', 'cognitiveservices']));\n      _this._lang = typeof window !== 'undefined' ? window.document.documentElement.getAttribute('lang') || window.navigator.language : 'en-US';\n      _this.readyState = 0;\n      _this.createRecognizer = (0, _memoizeOne.default)(function (language) {\n        var mode = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : CognitiveSpeech.RecognitionMode.Interactive;\n        var osPlatform = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : window.navigator.userAgent;\n        var osName = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : window.navigator.appName;\n        var osVersion = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : window.navigator.appVersion;\n        var deviceManufacturer = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 'microsoft-speech-browser-sdk';\n        var deviceModel = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 'web-speech-cognitive-services';\n        var deviceVersion = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : \"4.0.0\";\n        var config = new CognitiveSpeech.RecognizerConfig(new CognitiveSpeech.SpeechConfig(new CognitiveSpeech.Context(new CognitiveSpeech.OS(osPlatform, osName, osVersion), new CognitiveSpeech.Device(deviceManufacturer, deviceModel, deviceVersion))), mode, language, CognitiveSpeech.SpeechResultFormat.Detailed);\n        var fetchToken;\n\n        if (authorizationToken) {\n          fetchToken = bingSpeechPromisify(\n          /*#__PURE__*/\n          (0, _asyncToGenerator2.default)(\n          /*#__PURE__*/\n          _regenerator.default.mark(function _callee() {\n            return _regenerator.default.wrap(function _callee$(_context) {\n              while (1) {\n                switch (_context.prev = _context.next) {\n                  case 0:\n                    if (!(typeof authorizationToken === 'function')) {\n                      _context.next = 6;\n                      break;\n                    }\n\n                    _context.next = 3;\n                    return authorizationToken();\n\n                  case 3:\n                    _context.t0 = _context.sent;\n                    _context.next = 7;\n                    break;\n\n                  case 6:\n                    _context.t0 = authorizationToken;\n\n                  case 7:\n                    return _context.abrupt(\"return\", _context.t0);\n\n                  case 8:\n                  case \"end\":\n                    return _context.stop();\n                }\n              }\n            }, _callee, this);\n          })));\n        } else if (subscriptionKey) {\n          fetchToken = bingSpeechPromisify(\n          /*#__PURE__*/\n          (0, _asyncToGenerator2.default)(\n          /*#__PURE__*/\n          _regenerator.default.mark(function _callee2() {\n            return _regenerator.default.wrap(function _callee2$(_context2) {\n              while (1) {\n                switch (_context2.prev = _context2.next) {\n                  case 0:\n                    return _context2.abrupt(\"return\", (0, _fetchAuthorizationToken.default)(subscriptionKey));\n\n                  case 1:\n                  case \"end\":\n                    return _context2.stop();\n                }\n              }\n            }, _callee2, this);\n          })));\n        }\n\n        return CognitiveSpeech.CreateRecognizer(config, new CognitiveSpeech.CognitiveTokenAuthentication(fetchToken, fetchToken));\n      });\n      return _this;\n    }\n\n    (0, _createClass2.default)(SpeechRecognition, [{\n      key: \"abort\",\n      value: function abort() {\n        // TODO: Should redesign how to stop a recognition session\n        //       After abort is called, we should not saw it is a \"success\", \"silent\", or \"no match\"\n        var _ref4 = this.recognizer || {},\n            AudioSource = _ref4.AudioSource;\n\n        AudioSource && AudioSource.TurnOff();\n        this._aborted = true;\n      }\n    }, {\n      key: \"emitCognitiveServices\",\n      value: function emitCognitiveServices(type, event) {\n        this.emit('cognitiveservices', (0, _objectSpread2.default)({}, event, {\n          subType: type\n        }));\n      }\n    }, {\n      key: \"stop\",\n      value: function stop() {\n        // TODO: Support stop\n        var _ref5 = this.recognizer || {},\n            AudioSource = _ref5.AudioSource;\n\n        AudioSource && AudioSource.TurnOff();\n      }\n    }, {\n      key: \"start\",\n      value: function () {\n        var _start = (0, _asyncToGenerator2.default)(\n        /*#__PURE__*/\n        _regenerator.default.mark(function _callee3() {\n          var recognizer, _toPromise, eventListener, promises, speechContext, recognitionTriggered, error, listeningStarted, connectingToService, recognitionStarted, gotFirstHypothesis, speechHypothesis, recognitionEnded, speechDetailedPhrase, recognitionResult, best, _recognitionEnded;\n\n          return _regenerator.default.wrap(function _callee3$(_context3) {\n            while (1) {\n              switch (_context3.prev = _context3.next) {\n                case 0:\n                  recognizer = this.recognizer = this.createRecognizer(this.lang, this.osPlatform || window.navigator.userAgent, this.osName || window.navigator.appName, this.osVersion || window.navigator.appVersion, this.deviceManufacturer || 'web-speech-cognitive-services', this.deviceModel || 'web-speech-cognitive-services', this.deviceVersion || \"4.0.0\");\n                  _toPromise = toPromise(), eventListener = _toPromise.eventListener, promises = (0, _objectWithoutProperties2.default)(_toPromise, [\"eventListener\"]);\n                  speechContext = this.grammars && this.grammars.createSpeechContext();\n                  recognizer.Recognize(eventListener, speechContext && JSON.stringify(speechContext));\n                  this._aborted = false;\n                  _context3.next = 7;\n                  return promises.recognitionTriggered;\n\n                case 7:\n                  recognitionTriggered = _context3.sent;\n                  this.emitCognitiveServices('recognitionTriggered', recognitionTriggered);\n                  _context3.next = 11;\n                  return Promise.race([promises.listeningStarted, promises.recognitionEnded]);\n\n                case 11:\n                  listeningStarted = _context3.sent;\n                  this.emitCognitiveServices(listeningStarted.Name === 'RecognitionEndedEvent' ? 'recognitionEnded' : ' listeningStarted', listeningStarted);\n\n                  if (!(listeningStarted.Name === 'RecognitionEndedEvent')) {\n                    _context3.next = 17;\n                    break;\n                  } // Possibly not authorized to use microphone\n\n\n                  if (listeningStarted.Status === CognitiveSpeech.RecognitionCompletionStatus.AudioSourceError) {\n                    error = 'not-allowed';\n                  } else {\n                    error = CognitiveSpeech.RecognitionCompletionStatus[listeningStarted.Status];\n                  }\n\n                  _context3.next = 62;\n                  break;\n\n                case 17:\n                  this.emit('start');\n                  _context3.next = 20;\n                  return promises.connectingToService;\n\n                case 20:\n                  connectingToService = _context3.sent;\n                  this.emitCognitiveServices('connectingToService', connectingToService);\n                  _context3.next = 24;\n                  return Promise.race([promises.recognitionStarted, promises.recognitionEnded]);\n\n                case 24:\n                  recognitionStarted = _context3.sent;\n                  this.emitCognitiveServices(recognitionStarted.Name === 'RecognitionEndedEvent' ? 'recognitionEnded' : 'recognitionStarted', recognitionStarted);\n                  this.emit('audiostart');\n\n                  if (!(recognitionStarted.Name === 'RecognitionEndedEvent')) {\n                    _context3.next = 31;\n                    break;\n                  } // Possibly network error\n\n\n                  if (recognitionStarted.Status === CognitiveSpeech.RecognitionCompletionStatus.ConnectError) {\n                    error = 'network';\n                  } else {\n                    error = CognitiveSpeech.RecognitionCompletionStatus[recognitionStarted.Status];\n                  }\n\n                  _context3.next = 42;\n                  break;\n\n                case 31:\n                  _context3.next = 33;\n                  return Promise.race([promises.getSpeechHypothesisPromise(), promises.speechEndDetected]);\n\n                case 33:\n                  speechHypothesis = _context3.sent;\n                  this.emitCognitiveServices(speechHypothesis.Name === 'SpeechEndDetectedEvent' ? 'speechEndDetected' : 'speechHypothesis', speechHypothesis);\n\n                  if (!(speechHypothesis.Name === 'SpeechEndDetectedEvent')) {\n                    _context3.next = 37;\n                    break;\n                  }\n\n                  return _context3.abrupt(\"break\", 41);\n\n                case 37:\n                  if (!gotFirstHypothesis) {\n                    gotFirstHypothesis = true;\n                    this.emit('soundstart');\n                    this.emit('speechstart');\n                  }\n\n                  this.emit('result', buildSpeechResult(speechHypothesis.Result.Text, .5, false));\n\n                case 39:\n                  _context3.next = 31;\n                  break;\n\n                case 41:\n                  if (gotFirstHypothesis) {\n                    this.emit('speechend');\n                    this.emit('soundend');\n                  }\n\n                case 42:\n                  this.emit('audioend');\n\n                  if (!this._aborted) {\n                    _context3.next = 51;\n                    break;\n                  }\n\n                  error = 'aborted';\n                  _context3.next = 47;\n                  return promises.recognitionEnded;\n\n                case 47:\n                  recognitionEnded = _context3.sent;\n                  this.emitCognitiveServices('recognitionEnded', recognitionEnded);\n                  _context3.next = 62;\n                  break;\n\n                case 51:\n                  _context3.next = 53;\n                  return Promise.race([promises.speechDetailedPhrase, promises.recognitionEnded]);\n\n                case 53:\n                  speechDetailedPhrase = _context3.sent;\n                  this.emitCognitiveServices(speechDetailedPhrase.Name === 'RecognitionEndedEvent' ? 'recognitionEnded' : 'speechDetailedPhrase', speechDetailedPhrase);\n\n                  if (!(speechDetailedPhrase.Name !== 'RecognitionEndedEvent')) {\n                    _context3.next = 62;\n                    break;\n                  }\n\n                  recognitionResult = CognitiveSpeech.RecognitionStatus[speechDetailedPhrase.Result.RecognitionStatus];\n\n                  if (recognitionResult === CognitiveSpeech.RecognitionStatus.Success) {\n                    // TODO: [P2] Support maxAlternatives\n                    best = speechDetailedPhrase.Result.NBest[0];\n                    this.emit('result', buildSpeechResult(textNormalization === 'itn' ? best.ITN : textNormalization === 'lexical' ? best.Lexical : textNormalization === 'maskeditn' ? best.MaskedITN : best.Display, best.Confidence, true));\n                  } else if (recognitionResult !== CognitiveSpeech.RecognitionStatus.NoMatch) {\n                    // Possibly silent or muted\n                    if (recognitionResult === CognitiveSpeech.RecognitionStatus.InitialSilenceTimeout) {\n                      error = 'no-speech';\n                    } else {\n                      error = speechDetailedPhrase.Result.RecognitionStatus;\n                    }\n                  }\n\n                  _context3.next = 60;\n                  return promises.recognitionEnded;\n\n                case 60:\n                  _recognitionEnded = _context3.sent;\n                  this.emitCognitiveServices('recognitionEnded', _recognitionEnded);\n\n                case 62:\n                  error && this.emit('error', {\n                    error: error\n                  });\n                  this.emit('end');\n\n                case 64:\n                case \"end\":\n                  return _context3.stop();\n              }\n            }\n          }, _callee3, this);\n        }));\n\n        return function start() {\n          return _start.apply(this, arguments);\n        };\n      }()\n    }, {\n      key: \"grammars\",\n      get: function get() {\n        return this._grammars;\n      },\n      set: function set(nextGrammars) {\n        if (nextGrammars && !(nextGrammars instanceof _SpeechGrammarList.default)) {\n          throw new Error('must be instance of SpeechGrammarList from \"web-speech-cognitive-services\"');\n        }\n\n        this._grammars = nextGrammars;\n      }\n    }, {\n      key: \"lang\",\n      get: function get() {\n        return this._lang;\n      },\n      set: function set(nextLang) {\n        this._lang = nextLang;\n      }\n    }, {\n      key: \"continuous\",\n      get: function get() {\n        return false;\n      },\n      set: function set(nextContinuous) {\n        nextContinuous && console.warn(\"Bing Speech: Cannot set continuous to \".concat(nextContinuous, \", this feature is not supported.\"));\n      }\n    }, {\n      key: \"interimResults\",\n      get: function get() {\n        return true;\n      },\n      set: function set(nextInterimResults) {\n        !nextInterimResults && console.warn(\"Bing Speech: Cannot set interimResults to \".concat(nextInterimResults, \", this feature is not supported.\"));\n      }\n    }, {\n      key: \"maxAlternatives\",\n      get: function get() {\n        return 1;\n      },\n      set: function set(nextMaxAlternatives) {\n        nextMaxAlternatives !== 1 && console.warn(\"Bing Speech: Cannot set maxAlternatives to \".concat(nextMaxAlternatives, \", this feature is not supported.\"));\n      }\n    }, {\n      key: \"serviceURI\",\n      get: function get() {\n        return null;\n      },\n      set: function set(nextServiceURI) {\n        nextServiceURI && console.warn(\"Bing Speech: Cannot set serviceURI to \".concat(nextServiceURI, \", this feature is not supported.\"));\n      }\n    }]);\n    return SpeechRecognition;\n  }(_DOMEventEmitter2.default);\n\n  return {\n    SpeechGrammarList: _SpeechGrammarList.default,\n    SpeechRecognition: SpeechRecognition\n  };\n};\n\nexports.default = _default;\n\nfunction toPromise() {\n  var events = {\n    ConnectingToServiceEvent: new _eventAsPromise.default(),\n    ListeningStartedEvent: new _eventAsPromise.default(),\n    RecognitionEndedEvent: new _eventAsPromise.default(),\n    RecognitionStartedEvent: new _eventAsPromise.default(),\n    RecognitionTriggeredEvent: new _eventAsPromise.default(),\n    SpeechDetailedPhraseEvent: new _eventAsPromise.default(),\n    SpeechEndDetectedEvent: new _eventAsPromise.default(),\n    SpeechHypothesisEvent: new _eventAsPromise.default(),\n    SpeechSimplePhraseEvent: new _eventAsPromise.default(),\n    SpeechStartDetectedEvent: new _eventAsPromise.default()\n  };\n  return {\n    connectingToService: events.ConnectingToServiceEvent.upcoming(),\n    listeningStarted: events.ListeningStartedEvent.upcoming(),\n    recognitionEnded: events.RecognitionEndedEvent.upcoming(),\n    recognitionStarted: events.RecognitionStartedEvent.upcoming(),\n    recognitionTriggered: events.RecognitionTriggeredEvent.upcoming(),\n    speechDetailedPhrase: events.SpeechDetailedPhraseEvent.upcoming(),\n    speechEndDetected: events.SpeechEndDetectedEvent.upcoming(),\n    getSpeechHypothesisPromise: function getSpeechHypothesisPromise() {\n      return events.SpeechHypothesisEvent.upcoming();\n    },\n    speechSimplePhrase: events.SpeechSimplePhraseEvent.upcoming(),\n    speechStartDetected: events.SpeechStartDetectedEvent.upcoming(),\n    eventListener: function eventListener(event) {\n      var name = event.Name;\n      var eventAsPromise = events[name];\n\n      if (eventAsPromise) {\n        eventAsPromise.eventListener.call(null, event);\n      } else {\n        console.warn(\"Unexpected event \\\"\".concat(name, \"\\\" from Cognitive Services, please file a bug to https://github.com/compulim/web-speech-cognitive-services\"));\n      }\n    }\n  };\n}","map":null,"metadata":{},"sourceType":"script"}
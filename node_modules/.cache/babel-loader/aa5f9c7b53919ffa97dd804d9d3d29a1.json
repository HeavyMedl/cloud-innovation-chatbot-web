{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/objectSpread\"));\n\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\n\nvar _classCallCheck2 = _interopRequireDefault(require(\"@babel/runtime/helpers/classCallCheck\"));\n\nvar _createClass2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createClass\"));\n\nvar _possibleConstructorReturn2 = _interopRequireDefault(require(\"@babel/runtime/helpers/possibleConstructorReturn\"));\n\nvar _getPrototypeOf2 = _interopRequireDefault(require(\"@babel/runtime/helpers/getPrototypeOf\"));\n\nvar _inherits2 = _interopRequireDefault(require(\"@babel/runtime/helpers/inherits\"));\n\nvar _asyncToGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncToGenerator\"));\n\nvar _memoizeOne = _interopRequireDefault(require(\"memoize-one\"));\n\nvar _cognitiveServiceEventResultToWebSpeechRecognitionResultList = _interopRequireDefault(require(\"./cognitiveServiceEventResultToWebSpeechRecognitionResultList\"));\n\nvar _createPromiseQueue = _interopRequireDefault(require(\"../../Util/createPromiseQueue\"));\n\nvar _DOMEventEmitter2 = _interopRequireDefault(require(\"../../Util/DOMEventEmitter\"));\n\nvar _SpeechGrammarList = _interopRequireDefault(require(\"./SpeechGrammarList\"));\n\nvar _SpeechSDK = _interopRequireDefault(require(\"../SpeechSDK\")); // https://docs.microsoft.com/en-us/javascript/api/microsoft-cognitiveservices-speech-sdk/speechconfig?view=azure-node-latest#outputformat\n// {\n//   \"RecognitionStatus\": \"Success\",\n//   \"Offset\": 900000,\n//   \"Duration\": 49000000,\n//   \"NBest\": [\n//     {\n//       \"Confidence\": 0.738919,\n//       \"Lexical\": \"second\",\n//       \"ITN\": \"second\",\n//       \"MaskedITN\": \"second\",\n//       \"Display\": \"Second.\"\n//     }\n//   ]\n// }\n// {\n//   \"RecognitionStatus\": \"InitialSilenceTimeout\",\n//   \"Offset\": 50000000,\n//   \"Duration\": 0\n// }\n\n\nvar AudioConfig = _SpeechSDK.default.AudioConfig,\n    OutputFormat = _SpeechSDK.default.OutputFormat,\n    ResultReason = _SpeechSDK.default.ResultReason,\n    SpeechConfig = _SpeechSDK.default.SpeechConfig,\n    SpeechRecognizer = _SpeechSDK.default.SpeechRecognizer;\n\nfunction serializeRecognitionResult(_ref) {\n  var duration = _ref.duration,\n      errorDetails = _ref.errorDetails,\n      json = _ref.json,\n      offset = _ref.offset,\n      properties = _ref.properties,\n      reason = _ref.reason,\n      resultId = _ref.resultId,\n      text = _ref.text;\n  return {\n    duration: duration,\n    errorDetails: errorDetails,\n    json: JSON.parse(json),\n    offset: offset,\n    properties: properties,\n    reason: reason,\n    resultId: resultId,\n    text: text\n  };\n}\n\nvar _default =\n/*#__PURE__*/\n(0, _asyncToGenerator2.default)(\n/*#__PURE__*/\n_regenerator.default.mark(function _callee3() {\n  var _ref3,\n      authorizationToken,\n      _ref3$region,\n      region,\n      subscriptionKey,\n      _ref3$textNormalizati,\n      textNormalization,\n      audioConfig,\n      SpeechRecognition,\n      _args4 = arguments;\n\n  return _regenerator.default.wrap(function _callee3$(_context4) {\n    while (1) {\n      switch (_context4.prev = _context4.next) {\n        case 0:\n          _ref3 = _args4.length > 0 && _args4[0] !== undefined ? _args4[0] : {}, authorizationToken = _ref3.authorizationToken, _ref3$region = _ref3.region, region = _ref3$region === void 0 ? 'westus' : _ref3$region, subscriptionKey = _ref3.subscriptionKey, _ref3$textNormalizati = _ref3.textNormalization, textNormalization = _ref3$textNormalizati === void 0 ? 'display' : _ref3$textNormalizati;\n\n          if (!(!authorizationToken && !subscriptionKey)) {\n            _context4.next = 6;\n            break;\n          }\n\n          console.warn('Either authorizationToken or subscriptionKey must be specified');\n          return _context4.abrupt(\"return\", {});\n\n        case 6:\n          if (!(!window.navigator.mediaDevices || !window.navigator.mediaDevices.getUserMedia)) {\n            _context4.next = 9;\n            break;\n          }\n\n          console.warn('This browser does not support WebRTC and it will not work with Cognitive Services Speech Services.');\n          return _context4.abrupt(\"return\", {});\n\n        case 9:\n          audioConfig = AudioConfig.fromDefaultMicrophoneInput();\n\n          SpeechRecognition =\n          /*#__PURE__*/\n          function (_DOMEventEmitter) {\n            (0, _inherits2.default)(SpeechRecognition, _DOMEventEmitter);\n\n            function SpeechRecognition() {\n              var _this;\n\n              (0, _classCallCheck2.default)(this, SpeechRecognition);\n              _this = (0, _possibleConstructorReturn2.default)(this, (0, _getPrototypeOf2.default)(SpeechRecognition).call(this, ['audiostart', 'soundstart', 'speechstart', 'speechend', 'soundend', 'audioend', 'result', 'nomatch', 'error', 'start', 'end', 'cognitiveservices']));\n              _this._continuous = false;\n              _this._interimResults = false;\n              _this._lang = typeof window !== 'undefined' ? window.document.documentElement.getAttribute('lang') || window.navigator.language : 'en-US';\n              _this._maxAlternatives = 1;\n              return _this;\n            }\n\n            (0, _createClass2.default)(SpeechRecognition, [{\n              key: \"createRecognizer\",\n              value: function () {\n                var _createRecognizer = (0, _asyncToGenerator2.default)(\n                /*#__PURE__*/\n                _regenerator.default.mark(function _callee() {\n                  var speechConfig;\n                  return _regenerator.default.wrap(function _callee$(_context) {\n                    while (1) {\n                      switch (_context.prev = _context.next) {\n                        case 0:\n                          if (!authorizationToken) {\n                            _context.next = 16;\n                            break;\n                          }\n\n                          _context.t1 = SpeechConfig;\n\n                          if (!(typeof authorizationToken === 'function')) {\n                            _context.next = 8;\n                            break;\n                          }\n\n                          _context.next = 5;\n                          return authorizationToken();\n\n                        case 5:\n                          _context.t2 = _context.sent;\n                          _context.next = 11;\n                          break;\n\n                        case 8:\n                          _context.next = 10;\n                          return authorizationToken;\n\n                        case 10:\n                          _context.t2 = _context.sent;\n\n                        case 11:\n                          _context.t3 = _context.t2;\n                          _context.t4 = region;\n                          _context.t0 = _context.t1.fromAuthorizationToken.call(_context.t1, _context.t3, _context.t4);\n                          _context.next = 17;\n                          break;\n\n                        case 16:\n                          _context.t0 = SpeechConfig.fromSubscription(subscriptionKey, region);\n\n                        case 17:\n                          speechConfig = _context.t0;\n                          speechConfig.outputFormat = OutputFormat.Detailed;\n                          speechConfig.speechRecognitionLanguage = this.lang || 'en-US';\n                          return _context.abrupt(\"return\", new SpeechRecognizer(speechConfig, audioConfig));\n\n                        case 21:\n                        case \"end\":\n                          return _context.stop();\n                      }\n                    }\n                  }, _callee, this);\n                }));\n\n                return function createRecognizer() {\n                  return _createRecognizer.apply(this, arguments);\n                };\n              }()\n            }, {\n              key: \"emitCognitiveServices\",\n              value: function emitCognitiveServices(type, event) {\n                this.emit('cognitiveservices', (0, _objectSpread2.default)({}, event, {\n                  subType: type\n                }));\n              }\n            }, {\n              key: \"abort\",\n              value: function abort() {}\n            }, {\n              key: \"start\",\n              value: function start() {\n                var _this2 = this;\n\n                if (this.continuous) {\n                  throw new Error('Continuous mode is not supported.');\n                } else {\n                  this._startOnce().catch(function (err) {\n                    console.error(err);\n\n                    _this2.emit('error', {\n                      error: err,\n                      message: err && err.message\n                    });\n                  });\n                }\n              }\n            }, {\n              key: \"_startOnce\",\n              value: function () {\n                var _startOnce2 = (0, _asyncToGenerator2.default)(\n                /*#__PURE__*/\n                _regenerator.default.mark(function _callee2() {\n                  var _this3 = this;\n\n                  var recognizer, queue, lastRecognizingResults, speechStarted, stopping, audioStarted, finalEvent, _loop, loop, _ret;\n\n                  return _regenerator.default.wrap(function _callee2$(_context3) {\n                    while (1) {\n                      switch (_context3.prev = _context3.next) {\n                        case 0:\n                          _context3.next = 2;\n                          return this.createRecognizer();\n\n                        case 2:\n                          recognizer = _context3.sent;\n                          queue = (0, _createPromiseQueue.default)();\n\n                          recognizer.canceled = function (_, _ref4) {\n                            var errorDetails = _ref4.errorDetails,\n                                offset = _ref4.offset,\n                                reason = _ref4.reason,\n                                sessionId = _ref4.sessionId;\n                            queue.push({\n                              canceled: {\n                                errorDetails: errorDetails,\n                                offset: offset,\n                                reason: reason,\n                                sessionId: sessionId\n                              }\n                            });\n                          };\n\n                          recognizer.recognized = function (_, _ref5) {\n                            var offset = _ref5.offset,\n                                result = _ref5.result,\n                                sessionId = _ref5.sessionId;\n                            queue.push({\n                              recognized: {\n                                offset: offset,\n                                result: serializeRecognitionResult(result),\n                                sessionId: sessionId\n                              }\n                            });\n                          };\n\n                          recognizer.recognizing = function (_, _ref6) {\n                            var offset = _ref6.offset,\n                                result = _ref6.result,\n                                sessionId = _ref6.sessionId;\n                            queue.push({\n                              recognizing: {\n                                offset: offset,\n                                result: serializeRecognitionResult(result),\n                                sessionId: sessionId\n                              }\n                            });\n                          };\n\n                          recognizer.recognizeOnceAsync(function (result) {\n                            return queue.push({\n                              success: serializeRecognitionResult(result)\n                            });\n                          }, function (err) {\n                            return queue.push({\n                              error: err\n                            });\n                          });\n\n                          this.abort = function () {\n                            return queue.push({\n                              abort: {}\n                            });\n                          };\n\n                          this.stop = function () {\n                            return queue.push({\n                              stop: {}\n                            });\n                          };\n\n                          _loop =\n                          /*#__PURE__*/\n                          _regenerator.default.mark(function _loop(loop) {\n                            var event, abort, canceled, error, recognized, recognizing, stop, success, errorMessage;\n                            return _regenerator.default.wrap(function _loop$(_context2) {\n                              while (1) {\n                                switch (_context2.prev = _context2.next) {\n                                  case 0:\n                                    _context2.next = 2;\n                                    return queue.shift();\n\n                                  case 2:\n                                    event = _context2.sent;\n                                    abort = event.abort, canceled = event.canceled, error = event.error, recognized = event.recognized, recognizing = event.recognizing, stop = event.stop, success = event.success; // We are emitting event \"cognitiveservices\" for debugging purpose\n\n                                    Object.keys(event).forEach(function (name) {\n                                      return _this3.emitCognitiveServices(name, event[name]);\n                                    });\n                                    errorMessage = error ? error : canceled && canceled.errorDetails;\n\n                                    if (!(errorMessage && /Permission\\sdenied/.test(errorMessage))) {\n                                      _context2.next = 9;\n                                      break;\n                                    }\n\n                                    finalEvent = {\n                                      error: 'not-allowed',\n                                      type: 'error'\n                                    };\n                                    return _context2.abrupt(\"return\", \"break\");\n\n                                  case 9:\n                                    if (!loop) {\n                                      _this3.emit('start');\n\n                                      _this3.emit('audiostart');\n\n                                      audioStarted = true;\n                                    }\n\n                                    if (!errorMessage) {\n                                      _context2.next = 15;\n                                      break;\n                                    }\n\n                                    if (/1006/.test(errorMessage)) {\n                                      finalEvent = {\n                                        error: 'network',\n                                        type: 'error'\n                                      };\n                                    } else {\n                                      finalEvent = {\n                                        error: 'unknown',\n                                        type: 'error'\n                                      };\n                                    }\n\n                                    return _context2.abrupt(\"return\", \"break\");\n\n                                  case 15:\n                                    if (!(abort || stop)) {\n                                      _context2.next = 21;\n                                      break;\n                                    }\n\n                                    stopping = true;\n\n                                    if (abort) {\n                                      finalEvent = {\n                                        error: 'aborted',\n                                        type: 'error'\n                                      };\n                                    } else if (lastRecognizingResults) {\n                                      lastRecognizingResults.isFinal = true;\n                                      finalEvent = {\n                                        results: lastRecognizingResults,\n                                        type: 'result'\n                                      };\n                                    }\n\n                                    if (speechStarted) {\n                                      _this3.emit('speechend');\n\n                                      _this3.emit('soundend');\n\n                                      speechStarted = false;\n                                    }\n\n                                    _context2.next = 33;\n                                    break;\n\n                                  case 21:\n                                    if (stopping) {\n                                      _context2.next = 33;\n                                      break;\n                                    }\n\n                                    if (!(recognized && recognized.result && recognized.result.reason === ResultReason.NoMatch)) {\n                                      _context2.next = 26;\n                                      break;\n                                    }\n\n                                    finalEvent = {\n                                      error: 'no-speech',\n                                      type: 'error'\n                                    };\n                                    _context2.next = 33;\n                                    break;\n\n                                  case 26:\n                                    if (!loop) {\n                                      _this3.emit('soundstart');\n\n                                      _this3.emit('speechstart');\n\n                                      speechStarted = true;\n                                    }\n\n                                    if (!recognized) {\n                                      _context2.next = 32;\n                                      break;\n                                    }\n\n                                    finalEvent = {\n                                      results: (0, _cognitiveServiceEventResultToWebSpeechRecognitionResultList.default)(recognized.result, {\n                                        maxAlternatives: _this3.maxAlternatives,\n                                        textNormalization: textNormalization\n                                      }),\n                                      type: 'result'\n                                    };\n                                    return _context2.abrupt(\"return\", \"break\");\n\n                                  case 32:\n                                    if (recognizing) {\n                                      lastRecognizingResults = (0, _cognitiveServiceEventResultToWebSpeechRecognitionResultList.default)(recognizing.result, {\n                                        maxAlternatives: _this3.maxAlternatives,\n                                        textNormalization: textNormalization\n                                      });\n                                      _this3.interimResults && _this3.emit('result', {\n                                        results: lastRecognizingResults\n                                      });\n                                    }\n\n                                  case 33:\n                                    if (!(error || success)) {\n                                      _context2.next = 35;\n                                      break;\n                                    }\n\n                                    return _context2.abrupt(\"return\", \"break\");\n\n                                  case 35:\n                                  case \"end\":\n                                    return _context2.stop();\n                                }\n                              }\n                            }, _loop, this);\n                          });\n                          loop = 0;\n\n                        case 12:\n                          return _context3.delegateYield(_loop(loop), \"t0\", 13);\n\n                        case 13:\n                          _ret = _context3.t0;\n\n                          if (!(_ret === \"break\")) {\n                            _context3.next = 16;\n                            break;\n                          }\n\n                          return _context3.abrupt(\"break\", 19);\n\n                        case 16:\n                          loop++;\n                          _context3.next = 12;\n                          break;\n\n                        case 19:\n                          // TODO: We should emit \"audioend\", \"result\", or \"error\" here\n                          //       This is for mimicking stop() behavior, \"audioend\" should not fire too early until we received the last \"recognized\" event\n                          if (speechStarted) {\n                            this.emit('speechend');\n                            this.emit('soundend');\n                          }\n\n                          if (audioStarted) {\n                            this.emit('audioend');\n                          }\n\n                          if (finalEvent) {\n                            this.emit(finalEvent.type, finalEvent);\n                          } // Even though there is no \"start\" event emitted, we will still emit \"end\" event\n                          // This is mainly for \"microphone blocked\" story.\n\n\n                          this.emit('end');\n                          recognizer.dispose();\n\n                        case 24:\n                        case \"end\":\n                          return _context3.stop();\n                      }\n                    }\n                  }, _callee2, this);\n                }));\n\n                return function _startOnce() {\n                  return _startOnce2.apply(this, arguments);\n                };\n              }()\n            }, {\n              key: \"stop\",\n              value: function stop() {}\n            }, {\n              key: \"continuous\",\n              get: function get() {\n                return this._continuous;\n              },\n              set: function set(value) {\n                value && console.warn(\"Speech Services: Cannot set continuous to \".concat(value, \", this feature is not supported.\"));\n              }\n            }, {\n              key: \"interimResults\",\n              get: function get() {\n                return this._interimResults;\n              },\n              set: function set(value) {\n                this._interimResults = value;\n              }\n            }, {\n              key: \"maxAlternatives\",\n              get: function get() {\n                return this._maxAlternatives;\n              },\n              set: function set(value) {\n                this._maxAlternatives = value;\n              }\n            }, {\n              key: \"lang\",\n              get: function get() {\n                return this._lang;\n              },\n              set: function set(value) {\n                this._lang = value;\n              }\n            }]);\n            return SpeechRecognition;\n          }(_DOMEventEmitter2.default);\n\n          return _context4.abrupt(\"return\", {\n            SpeechGrammarList: _SpeechGrammarList.default,\n            SpeechRecognition: SpeechRecognition\n          });\n\n        case 12:\n        case \"end\":\n          return _context4.stop();\n      }\n    }\n  }, _callee3, this);\n}));\n\nexports.default = _default;","map":null,"metadata":{},"sourceType":"script"}